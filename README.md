# llm-medical-chatbot
This is an offline chatbot that answers questions from a custom medical textbook PDF using Retrieval-Augmented Generation (RAG). It uses LangChain for orchestration, HuggingFace Transformers for local LLMs, FAISS for vector search, and Streamlit for UI.
## Features
- Offline RAG pipeline (no internet or API keys required)
- PDF ingestion and semantic search
- Local LLM with HuggingFace (`falcon-rw-1b`)
- UI built in Streamlit
- Privacy-friendly, cost-free
